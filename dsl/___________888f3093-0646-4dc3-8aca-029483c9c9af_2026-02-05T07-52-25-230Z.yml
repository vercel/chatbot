kind: app
version: 0.1.5
app:
  name: æ—¥æœ¬èªã‹ã‚‰ä¸­å›½èªå¤‰æ›
  description: æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’å—ã‘å–ã‚Šä¸­å›½èªã«ç¿»è¨³ã—ã¾ã™
  mode: advanced-chat
  icon: 'ğŸˆ¯ï¸'
  icon_background: '#FFCC00'
workflow:
  nodes:
  - id: start_node
    type: custom
    data:
      type: start
      variables:
      - type: text-input
        label: æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆ
        variable: input_text
        max_length: 1000
        required: true
    position:
      x: 0
      y: 0
    positionAbsolute:
      x: 0
      y: 0
    selected: false
    sourcePosition: right
    targetPosition: left
    width: 240
    height: 130
  - id: llm_node
    type: custom
    data:
      type: llm
      title: æ—¥æœ¬èªã‚’ä¸­å›½èªã«ç¿»è¨³
      prompt_template:
      - id: system
        role: system
        text: 'ã‚ãªãŸã¯ãƒ—ãƒ­ã®ç¿»è¨³è€…ã§ã™ã€‚æ—¥æœ¬èªã®æ–‡ç« ã‚’åˆ†ã‹ã‚Šã‚„ã™ãè‡ªç„¶ãªä¸­å›½èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚'
      - id: user
        role: user
        text: '{{#start_node.input_text#}}'
      completion_params:
        temperature: 0.7  # ç¿»è¨³ã¯å®‰å®šé‡è¦–ãªã®ã§æ¨™æº–ç¨‹åº¦ã®å‰µé€ æ€§
        max_tokens: 1000
        top_p: 1
        frequency_penalty: 0
        presence_penalty: 0
      model:
        provider: openai
        name: gpt-4o
        mode: chat
      context:
        enabled: false
        variable_selector: []
      selected: false
    position:
      x: 400
      y: 0
    positionAbsolute:
      x: 400
      y: 0
    sourcePosition: right
    targetPosition: left
    width: 300
    height: 300
  - id: answer_node
    type: custom
    data:
      type: answer
      title: ç¿»è¨³çµæœï¼ˆä¸­å›½èªï¼‰
      output_variable: text
      selected: false
    position:
      x: 800
      y: 0
    positionAbsolute:
      x: 800
      y: 0
    sourcePosition: right
    targetPosition: left
    width: 300
    height: 130
edges:
- id: edge_start_llm
  source: start_node
  target: llm_node
  sourceHandle: source
  targetHandle: target
  type: custom
  data:
    isInLoop: false
    isInIteration: false
- id: edge_llm_answer
  source: llm_node
  target: answer_node
  sourceHandle: source
  targetHandle: target
  type: custom
  data:
    isInLoop: false
    isInIteration: false
environment_variables: []
dependencies: []